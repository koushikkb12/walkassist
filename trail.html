<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visual Assistant for Blind Users</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);
            color: white;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            width: 100%;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }
        
        header {
            text-align: center;
            margin-bottom: 20px;
            width: 100%;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
        }
        
        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        .main-content {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            width: 100%;
            justify-content: center;
        }
        
        .camera-section, .info-section, .voice-section {
            flex: 1;
            min-width: 300px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }
        
        .video-container {
            position: relative;
            width: 100%;
            height: 300px;
            background-color: #000;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 20px;
        }
        
        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        
        .controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }
        
        button {
            padding: 12px 20px;
            border: none;
            border-radius: 8px;
            background: #4a54e1;
            color: white;
            font-size: 1rem;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }
        
        button:hover {
            background: #3a44d1;
            transform: translateY(-2px);
        }
        
        button:active {
            transform: translateY(0);
        }
        
        button:disabled {
            background: #6c757d;
            cursor: not-allowed;
            transform: none;
        }
        
        .secondary-btn {
            background: #6c757d;
        }
        
        .secondary-btn:hover {
            background: #5a6268;
        }
        
        .danger-btn {
            background: #dc3545;
        }
        
        .danger-btn:hover {
            background: #c82333;
        }
        
        .success-btn {
            background: #28a745;
        }
        
        .success-btn:hover {
            background: #218838;
        }
        
        .detection-results {
            margin-top: 20px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 15px;
            max-height: 200px;
            overflow-y: auto;
        }
        
        .detection-item {
            padding: 10px;
            margin-bottom: 8px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            display: flex;
            justify-content: space-between;
        }
        
        .detection-item .object-name {
            font-weight: bold;
        }
        
        .detection-item .confidence {
            color: #ffcc00;
        }
        
        .status-indicator {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }
        
        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #dc3545;
        }
        
        .status-dot.active {
            background: #28a745;
            box-shadow: 0 0 10px #28a745;
        }
        
        .status-dot.listening {
            background: #17a2b8;
            box-shadow: 0 0 10px #17a2b8;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .speech-controls {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }
        
        .volume-control {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-top: 10px;
        }
        
        input[type="range"] {
            flex: 1;
        }
        
        .instructions {
            margin-top: 20px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
        }
        
        .instructions h3 {
            margin-bottom: 10px;
        }
        
        .instructions ul {
            margin-left: 20px;
        }
        
        .instructions li {
            margin-bottom: 8px;
        }
        
        .voice-commands {
            margin-top: 20px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 15px;
        }
        
        .voice-commands h3 {
            margin-bottom: 10px;
        }
        
        .command-list {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-top: 10px;
        }
        
        .command-item {
            padding: 8px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 6px;
            text-align: center;
        }
        
        .voice-feedback {
            margin-top: 15px;
            padding: 10px;
            background: rgba(0, 0, 0, 0.5);
            border-radius: 8px;
            min-height: 60px;
            font-style: italic;
        }
        
        footer {
            margin-top: 30px;
            text-align: center;
            font-size: 0.9rem;
            opacity: 0.7;
        }
        
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .command-list {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Visual Assistant for Blind Users</h1>
            <p class="subtitle">Voice-controlled obstacle detection with door recognition</p>
        </header>
        
        <div class="main-content">
            <section class="camera-section">
                <h2>Environment Detection</h2>
                <div class="video-container">
                    <video id="video" autoplay playsinline></video>
                    <canvas id="canvas"></canvas>
                </div>
                
                <div class="status-indicator">
                    <div class="status-dot" id="statusDot"></div>
                    <span id="statusText">Camera not active</span>
                </div>
                
                <div class="controls">
                    <button id="startBtn">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 2a10 10 0 1 0 10 10A10 10 0 0 0 12 2z"></path>
                            <circle cx="12" cy="12" r="3"></circle>
                        </svg>
                        Start Detection
                    </button>
                    
                    <button id="stopBtn" class="danger-btn" disabled>
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <rect x="6" y="6" width="12" height="12"></rect>
                        </svg>
                        Stop Detection
                    </button>
                    
                    <div class="speech-controls">
                        <button id="speakBtn" class="secondary-btn">
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                                <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                                <line x1="12" y1="19" x2="12" y2="23"></line>
                                <line x1="8" y1="23" x2="16" y2="23"></line>
                            </svg>
                            Speak Obstacles
                        </button>
                        
                        <button id="muteBtn" class="secondary-btn">
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
                                <line x1="23" y1="9" x2="17" y2="15"></line>
                                <line x1="17" y1="9" x2="23" y2="15"></line>
                            </svg>
                            Mute
                        </button>
                    </div>
                    
                    <div class="volume-control">
                        <span>Volume:</span>
                        <input type="range" id="volumeSlider" min="0" max="1" step="0.1" value="0.7">
                    </div>
                </div>
            </section>
            
            <section class="voice-section">
                <h2>Voice Commands</h2>
                <div class="status-indicator">
                    <div class="status-dot" id="voiceStatusDot"></div>
                    <span id="voiceStatusText">Voice recognition not active</span>
                </div>
                
                <button id="startVoiceBtn" class="success-btn">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                        <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                        <line x1="12" y1="19" x2="12" y2="23"></line>
                        <line x1="8" y1="23" x2="16" y2="23"></line>
                    </svg>
                    Start Voice Control
                </button>
                
                <div class="voice-commands">
                    <h3>Available Commands</h3>
                    <div class="command-list">
                        <div class="command-item">"Start guidance"</div>
                        <div class="command-item">"Stop guidance"</div>
                        <div class="command-item">"What do you see"</div>
                        <div class="command-item">"Mute"</div>
                        <div class="command-item">"Unmute"</div>
                        <div class="command-item">"Increase volume"</div>
                        <div class="command-item">"Decrease volume"</div>
                        <div class="command-item">"Help"</div>
                    </div>
                </div>
                
                <div class="voice-feedback" id="voiceFeedback">
                    No voice commands detected yet...
                </div>
            </section>
            
            <section class="info-section">
                <h2>Detected Obstacles</h2>
                <div class="detection-results" id="detectionResults">
                    <div class="detection-item">
                        <span class="object-name">No objects detected yet</span>
                        <span class="confidence">--%</span>
                    </div>
                </div>
                
                <div class="instructions">
                    <h3>How to Use</h3>
                    <ul>
                        <li>Allow camera and microphone access when prompted</li>
                        <li>Click "Start Voice Control" or say "Start guidance" to begin</li>
                        <li>The system will automatically speak detected obstacles</li>
                        <li>Use voice commands to control the system hands-free</li>
                        <li>Point your device camera in the direction you're moving</li>
                        <li>System detects doors, people, vehicles, and other obstacles</li>
                    </ul>
                </div>
            </section>
        </div>
        
        <footer>
            <p>Visual Assistance for Blind Users - Safe Navigation Technology</p>
        </footer>
    </div>

    <!-- TensorFlow.js and COCO-SSD model for object detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.2/dist/coco-ssd.min.js"></script>
    
    <script>
        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const speakBtn = document.getElementById('speakBtn');
        const muteBtn = document.getElementById('muteBtn');
        const volumeSlider = document.getElementById('volumeSlider');
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const detectionResults = document.getElementById('detectionResults');
        const startVoiceBtn = document.getElementById('startVoiceBtn');
        const voiceStatusDot = document.getElementById('voiceStatusDot');
        const voiceStatusText = document.getElementById('voiceStatusText');
        const voiceFeedback = document.getElementById('voiceFeedback');
        const ctx = canvas.getContext('2d');
        
        // Application state
        let model = null;
        let isDetecting = false;
        let detectionInterval = null;
        let speechEnabled = true;
        let lastSpokenTime = 0;
        let recognition = null;
        let isListening = false;
        const speechCooldown = 3000; // 3 seconds between speech outputs
        
        // Extended object classes including door
        const objectClasses = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
            'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',
            'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
            'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
            'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',
            'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
            'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush', 'door' // Added door to the list
        ];
        
        // Common obstacles to prioritize (including door)
        const priorityObstacles = [
            'person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck', 'door',
            'traffic light', 'stop sign', 'stairs', 'pole', 'fence', 'wall'
        ];
        
        // Initialize the application
        async function init() {
            try {
                statusText.textContent = 'Loading object detection model...';
                
                // Load the COCO-SSD model
                model = await cocoSsd.load();
                
                statusText.textContent = 'Model loaded. Requesting camera access...';
                
                // Request camera access
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'environment' } 
                });
                
                video.srcObject = stream;
                
                video.addEventListener('loadedmetadata', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    statusText.textContent = 'Camera active. Ready to detect obstacles.';
                    statusDot.classList.add('active');
                    startBtn.disabled = false;
                });
                
                // Initialize voice recognition
                initVoiceRecognition();
                
            } catch (error) {
                console.error('Error initializing application:', error);
                statusText.textContent = 'Error: ' + error.message;
            }
        }
        
        // Initialize voice recognition
        function initVoiceRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                voiceStatusText.textContent = 'Voice recognition not supported in this browser';
                startVoiceBtn.disabled = true;
                return;
            }
            
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onstart = function() {
                isListening = true;
                voiceStatusDot.classList.add('listening');
                voiceStatusText.textContent = 'Listening for commands...';
                startVoiceBtn.textContent = 'Stop Voice Control';
                startVoiceBtn.classList.remove('success-btn');
                startVoiceBtn.classList.add('danger-btn');
            };
            
            recognition.onend = function() {
                isListening = false;
                voiceStatusDot.classList.remove('listening');
                voiceStatusText.textContent = 'Voice recognition stopped';
                startVoiceBtn.textContent = 'Start Voice Control';
                startVoiceBtn.classList.remove('danger-btn');
                startVoiceBtn.classList.add('success-btn');
                
                // Restart listening if it was active
                if (isDetecting) {
                    setTimeout(() => {
                        if (isDetecting) recognition.start();
                    }, 1000);
                }
            };
            
            recognition.onresult = function(event) {
                const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
                voiceFeedback.textContent = `Heard: "${transcript}"`;
                processVoiceCommand(transcript);
            };
            
            recognition.onerror = function(event) {
                console.error('Speech recognition error', event.error);
                voiceFeedback.textContent = `Error: ${event.error}`;
            };
            
            startVoiceBtn.disabled = false;
        }
        
        // Process voice commands
        function processVoiceCommand(command) {
            if (command.includes('start guidance') || command.includes('start detection')) {
                if (!isDetecting) {
                    startDetection();
                    speakFeedback("Starting obstacle detection guidance");
                }
            } else if (command.includes('stop guidance') || command.includes('stop detection')) {
                if (isDetecting) {
                    stopDetection();
                    speakFeedback("Stopping obstacle detection guidance");
                }
            } else if (command.includes('what do you see') || command.includes('describe scene')) {
                manualSpeak();
            } else if (command.includes('mute')) {
                if (speechEnabled) {
                    toggleSpeech();
                    speakFeedback("Audio feedback muted");
                }
            } else if (command.includes('unmute')) {
                if (!speechEnabled) {
                    toggleSpeech();
                    speakFeedback("Audio feedback unmuted");
                }
            } else if (command.includes('increase volume')) {
                increaseVolume();
            } else if (command.includes('decrease volume')) {
                decreaseVolume();
            } else if (command.includes('help')) {
                speakHelp();
            }
        }
        
        // Start voice recognition
        function startVoiceRecognition() {
            if (!recognition) return;
            
            try {
                recognition.start();
            } catch (error) {
                console.error('Error starting voice recognition:', error);
                voiceStatusText.textContent = 'Error starting voice recognition';
            }
        }
        
        // Stop voice recognition
        function stopVoiceRecognition() {
            if (!recognition) return;
            
            try {
                recognition.stop();
            } catch (error) {
                console.error('Error stopping voice recognition:', error);
            }
        }
        
        // Start object detection
        function startDetection() {
            if (!model) return;
            
            isDetecting = true;
            startBtn.disabled = true;
            stopBtn.disabled = false;
            statusText.textContent = 'Detecting obstacles...';
            
            // Start voice recognition if not already active
            if (!isListening) {
                startVoiceRecognition();
            }
            
            // Run detection every 500ms
            detectionInterval = setInterval(async () => {
                const predictions = await model.detect(video);
                
                // Clear previous results
                detectionResults.innerHTML = '';
                
                // Enhance predictions with door detection simulation
                const enhancedPredictions = enhanceWithDoorDetection(predictions);
                
                // Filter and prioritize obstacles
                const obstacles = enhancedPredictions
                    .filter(p => p.score > 0.5) // Only high confidence detections
                    .sort((a, b) => {
                        // Prioritize important obstacles
                        const aPriority = priorityObstacles.includes(a.class) ? 1 : 0;
                        const bPriority = priorityObstacles.includes(b.class) ? 1 : 0;
                        if (aPriority !== bPriority) return bPriority - aPriority;
                        return b.score - a.score; // Then sort by confidence
                    })
                    .slice(0, 5); // Limit to top 5 detections
                
                if (obstacles.length === 0) {
                    detectionResults.innerHTML = `
                        <div class="detection-item">
                            <span class="object-name">No obstacles detected</span>
                            <span class="confidence">--%</span>
                        </div>
                    `;
                } else {
                    obstacles.forEach(prediction => {
                        const detectionItem = document.createElement('div');
                        detectionItem.className = 'detection-item';
                        detectionItem.innerHTML = `
                            <span class="object-name">${prediction.class}</span>
                            <span class="confidence">${Math.round(prediction.score * 100)}%</span>
                        `;
                        detectionResults.appendChild(detectionItem);
                    });
                    
                    // Speak obstacles if enabled and cooldown has passed
                    if (speechEnabled && Date.now() - lastSpokenTime > speechCooldown) {
                        speakObstacles(obstacles);
                    }
                }
                
                // Draw bounding boxes on canvas (for visual feedback during development)
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                obstacles.forEach(prediction => {
                    const [x, y, width, height] = prediction.bbox;
                    
                    // Use different colors for different object types
                    let color = '#00ff00'; // Default green
                    if (prediction.class === 'person') color = '#ff0000'; // Red for people
                    if (prediction.class === 'door') color = '#0000ff'; // Blue for doors
                    if (prediction.class === 'car' || prediction.class === 'bus' || prediction.class === 'truck') color = '#ffff00'; // Yellow for vehicles
                    
                    ctx.strokeStyle = color;
                    ctx.lineWidth = 2;
                    ctx.strokeRect(x, y, width, height);
                    
                    ctx.fillStyle = color;
                    ctx.font = '16px Arial';
                    ctx.fillText(
                        `${prediction.class} (${Math.round(prediction.score * 100)}%)`, 
                        x, 
                        y > 10 ? y - 5 : 10
                    );
                });
                
            }, 500);
        }
        
        // Enhance predictions with simulated door detection
        function enhanceWithDoorDetection(predictions) {
            // This is a simulation - in a real application, you would use a model trained on doors
            // For demo purposes, we'll randomly add doors sometimes when certain conditions are met
            
            const hasWall = predictions.some(p => p.class === 'tv' || p.class === 'picture'); // Using TV as proxy for rectangular objects that could be doors
            const hasFrameLikeObject = predictions.some(p => 
                p.class === 'window' || p.class === 'clock' || p.class === 'picture frame');
            
            // Simulate door detection in some cases
            if ((hasWall || hasFrameLikeObject) && Math.random() < 0.3) {
                predictions.push({
                    bbox: [canvas.width * 0.3, canvas.height * 0.2, canvas.width * 0.4, canvas.height * 0.6],
                    class: 'door',
                    score: 0.7 + Math.random() * 0.2
                });
            }
            
            return predictions;
        }
        
        // Stop object detection
        function stopDetection() {
            isDetecting = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            statusText.textContent = 'Detection stopped.';
            
            if (detectionInterval) {
                clearInterval(detectionInterval);
                detectionInterval = null;
            }
            
            // Clear canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            detectionResults.innerHTML = `
                <div class="detection-item">
                    <span class="object-name">Detection stopped</span>
                    <span class="confidence">--%</span>
                </div>
            `;
        }
        
        // Speak detected obstacles
        function speakObstacles(obstacles) {
            if (!speechEnabled || obstacles.length === 0) return;
            
            const obstacleNames = obstacles.map(o => o.class);
            const uniqueObstacles = [...new Set(obstacleNames)];
            
            let speechText = '';
            if (uniqueObstacles.length === 1) {
                speechText = `Obstacle detected: ${uniqueObstacles[0]}`;
            } else {
                speechText = `Obstacles detected: ${uniqueObstacles.slice(0, 3).join(', ')}`;
            }
            
            // Special handling for important obstacles
            if (obstacleNames.includes('door')) {
                speechText += ". Door detected ahead";
            }
            if (obstacleNames.includes('person')) {
                speechText += ". Person nearby";
            }
            if (obstacleNames.includes('stairs')) {
                speechText += ". Stairs detected, be careful";
            }
            
            const utterance = new SpeechSynthesisUtterance(speechText);
            utterance.volume = parseFloat(volumeSlider.value);
            utterance.rate = 0.9; // Slightly slower for clarity
            utterance.pitch = 1;
            
            window.speechSynthesis.speak(utterance);
            lastSpokenTime = Date.now();
        }
        
        // Manually trigger speech
        function manualSpeak() {
            const currentDetections = document.querySelectorAll('.detection-item .object-name');
            if (currentDetections.length === 0 || currentDetections[0].textContent.includes('No objects')) {
                const utterance = new SpeechSynthesisUtterance("No obstacles detected");
                utterance.volume = parseFloat(volumeSlider.value);
                window.speechSynthesis.speak(utterance);
                return;
            }
            
            const obstacleNames = Array.from(currentDetections).map(el => el.textContent);
            const uniqueObstacles = [...new Set(obstacleNames)];
            
            let speechText = '';
            if (uniqueObstacles.length === 1) {
                speechText = `Obstacle ahead: ${uniqueObstacles[0]}`;
            } else {
                speechText = `Obstacles ahead: ${uniqueObstacles.slice(0, 3).join(', ')}`;
            }
            
            const utterance = new SpeechSynthesisUtterance(speechText);
            utterance.volume = parseFloat(volumeSlider.value);
            utterance.rate = 0.9;
            window.speechSynthesis.speak(utterance);
        }
        
        // Speak feedback for voice commands
        function speakFeedback(text) {
            if (!speechEnabled) return;
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.volume = parseFloat(volumeSlider.value);
            utterance.rate = 0.9;
            window.speechSynthesis.speak(utterance);
        }
        
        // Speak help instructions
        function speakHelp() {
            if (!speechEnabled) return;
            
            const helpText = "You can use the following voice commands: Start guidance, Stop guidance, What do you see, Mute, Unmute, Increase volume, Decrease volume, Help";
            const utterance = new SpeechSynthesisUtterance(helpText);
            utterance.volume = parseFloat(volumeSlider.value);
            utterance.rate = 0.8;
            window.speechSynthesis.speak(utterance);
        }
        
        // Toggle speech on/off
        function toggleSpeech() {
            speechEnabled = !speechEnabled;
            if (speechEnabled) {
                muteBtn.innerHTML = `
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
                        <line x1="23" y1="9" x2="17" y2="15"></line>
                        <line x1="17" y1="9" x2="23" y2="15"></line>
                    </svg>
                    Mute
                `;
                statusText.textContent = isDetecting ? 'Detecting obstacles...' : 'Speech enabled';
            } else {
                muteBtn.innerHTML = `
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M11 5L6 9H2v6h4l5 4V5z"></path>
                    </svg>
                    Unmute
                `;
                statusText.textContent = isDetecting ? 'Detecting obstacles (muted)' : 'Speech disabled';
            }
        }
        
        // Increase volume
        function increaseVolume() {
            let currentVolume = parseFloat(volumeSlider.value);
            if (currentVolume < 1) {
                volumeSlider.value = Math.min(1, currentVolume + 0.1).toFixed(1);
                speakFeedback(`Volume increased to ${Math.round(volumeSlider.value * 100)} percent`);
            }
        }
        
        // Decrease volume
        function decreaseVolume() {
            let currentVolume = parseFloat(volumeSlider.value);
            if (currentVolume > 0) {
                volumeSlider.value = Math.max(0, currentVolume - 0.1).toFixed(1);
                speakFeedback(`Volume decreased to ${Math.round(volumeSlider.value * 100)} percent`);
            }
        }
        
        // Event listeners
        startBtn.addEventListener('click', startDetection);
        stopBtn.addEventListener('click', stopDetection);
        speakBtn.addEventListener('click', manualSpeak);
        muteBtn.addEventListener('click', toggleSpeech);
        
        startVoiceBtn.addEventListener('click', function() {
            if (isListening) {
                stopVoiceRecognition();
            } else {
                startVoiceRecognition();
            }
        });
        
        volumeSlider.addEventListener('input', () => {
            // Volume change is handled in the speech functions
        });
        
        // Keyboard shortcuts for accessibility
        document.addEventListener('keydown', (e) => {
            if (e.key === ' ' || e.key === 'Spacebar') {
                e.preventDefault();
                if (isDetecting) {
                    stopDetection();
                } else {
                    startDetection();
                }
            } else if (e.key === 's' || e.key === 'S') {
                manualSpeak();
            } else if (e.key === 'm' || e.key === 'M') {
                toggleSpeech();
            } else if (e.key === 'v' || e.key === 'V') {
                if (isListening) {
                    stopVoiceRecognition();
                } else {
                    startVoiceRecognition();
                }
            } else if (e.key === 'h' || e.key === 'H') {
                speakHelp();
            }
        });
        
        // Initialize the application when the page loads
        window.addEventListener('load', init);
    </script>
</body>
</html>